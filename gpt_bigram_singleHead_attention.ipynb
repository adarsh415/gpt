{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBedQMyvaTIDOjkpToDp5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh415/gpt/blob/main/gpt_bigram_singleHead_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3feIKpsj4zP",
        "outputId": "a885af4b-6392-4df2-eb02-13ea03dd3e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-22 17:40:58--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.3’\n",
            "\n",
            "\rinput.txt.3           0%[                    ]       0  --.-KB/s               \rinput.txt.3         100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-22 17:40:58 (38.8 MB/s) - ‘input.txt.3’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "hrOTjzPlkQZC"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVgczUeMkjZQ",
        "outputId": "0656cc23-61d3-4bce-938a-f53da9a62541"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AeiyqN3kxfi",
        "outputId": "cb0a135c-a1a8-45fa-8daf-656a7fed6f59"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all unique characters that occurs in text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNUqoBV_k5P8",
        "outputId": "d204e759-48e7-4e66-ebb1-53000edfc86e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping from characters to integers\n",
        "stoi = {ch:i for i, ch in enumerate(chars)}\n",
        "itos = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: takes a string, returns sequence of intgers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: takes list of integers, outputs string\n",
        "\n",
        "print(encode('hii there'))\n",
        "print(decode(encode('hii there')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4iSKzylUWt",
        "outputId": "622d61ce-27b8-407b-886d-8a585768fa1d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Hncx_kFsly_f"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32 # how many independent sequences will process in parallel\n",
        "block_size=8 # what is the maximum context length of predictions?\n",
        "n_embed = 32\n",
        "lr_rate = 1e-3\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "max_iters = 5000"
      ],
      "metadata": {
        "id": "wABAcoSvp90f"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V7tdNHflVan",
        "outputId": "c4b13438-8eee-4cc5-9629-1012a17d4a5c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's split dataset into train and validation set\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "GYih96aap3KU"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZXpoSxqQLd",
        "outputId": "81edf823-7777-429d-b335-3d5e0fa67a0b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when context is: {context} target is: {target}\")"
      ],
      "metadata": {
        "id": "LmKrlNZ7qvBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897cddfe-c69f-451e-c6bd-713f5ad1bca7"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when context is: tensor([18]) target is: 47\n",
            "when context is: tensor([18, 47]) target is: 56\n",
            "when context is: tensor([18, 47, 56]) target is: 57\n",
            "when context is: tensor([18, 47, 56, 57]) target is: 58\n",
            "when context is: tensor([18, 47, 56, 57, 58]) target is: 1\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1]) target is: 15\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1, 15]) target is: 47\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1023)\n",
        "def get_batch(split):\n",
        "  data = train_data if split=='train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('target')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('---------')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "    print(f\"when context is: {context.tolist()} target is: {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvBQggSPe7Uw",
        "outputId": "fa5b586a-a8ee-463f-be2a-ba95b90e228e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "torch.Size([32, 8])\n",
            "tensor([[53,  1, 40, 43,  1, 58, 39, 50],\n",
            "        [ 1, 42, 53,  1, 52, 53, 58,  1],\n",
            "        [47, 58,  1, 47, 57,  1, 52, 53],\n",
            "        [25, 13, 30, 19, 13, 30, 17, 32],\n",
            "        [43,  1, 39, 58,  1, 58, 46, 63],\n",
            "        [46, 47, 57,  1, 46, 53, 50, 63],\n",
            "        [ 0, 26, 53, 61,  1, 57, 61, 39],\n",
            "        [ 1, 52, 39, 51, 43,  1, 40, 43],\n",
            "        [ 0, 25, 17, 26, 17, 26, 21, 33],\n",
            "        [13, 16, 37,  1, 19, 30, 17, 37],\n",
            "        [ 1, 59, 54,  1, 58, 46, 43,  1],\n",
            "        [45, 46, 52, 43, 57, 57,  6,  1],\n",
            "        [53, 10,  0, 61, 46, 63,  6,  1],\n",
            "        [48, 53, 47, 52,  5, 42,  0, 14],\n",
            "        [42,  8,  0,  0, 19, 24, 27, 33],\n",
            "        [46, 39, 58,  1, 24, 43, 61, 47],\n",
            "        [43, 56, 43,  2,  0,  0, 14, 33],\n",
            "        [35, 43, 50, 41, 53, 51, 43,  6],\n",
            "        [26, 34, 27, 24, 21, 27, 10,  0],\n",
            "        [57,  1, 40, 50, 47, 52, 42,  1],\n",
            "        [58, 46, 43, 56,  1, 57, 58, 39],\n",
            "        [51, 39, 50, 50,  1, 39, 50, 43],\n",
            "        [43, 58, 41, 46,  1, 57, 46, 56],\n",
            "        [39, 51,  1, 63, 53, 59, 56, 57],\n",
            "        [ 1, 58, 46, 43,  1, 57, 46, 43],\n",
            "        [43,  1, 53, 56,  1, 61, 39, 56],\n",
            "        [58, 56, 47, 49, 43, 57, 58,  1],\n",
            "        [ 1, 51, 43, 56, 41, 43, 52, 39],\n",
            "        [26, 15, 17, 10,  0, 13,  1, 50],\n",
            "        [58,  1, 21,  1, 61, 53, 59, 50],\n",
            "        [52, 43,  1, 43, 63, 43, 57,  8],\n",
            "        [ 1, 39, 52, 42,  1, 41, 53, 59]])\n",
            "target\n",
            "torch.Size([32, 8])\n",
            "tensor([[ 1, 40, 43,  1, 58, 39, 50, 49],\n",
            "        [42, 53,  1, 52, 53, 58,  1, 46],\n",
            "        [58,  1, 47, 57,  1, 52, 53, 61],\n",
            "        [13, 30, 19, 13, 30, 17, 32, 10],\n",
            "        [ 1, 39, 58,  1, 58, 46, 63,  1],\n",
            "        [47, 57,  1, 46, 53, 50, 63,  1],\n",
            "        [26, 53, 61,  1, 57, 61, 39, 50],\n",
            "        [52, 39, 51, 43,  1, 40, 43,  1],\n",
            "        [25, 17, 26, 17, 26, 21, 33, 31],\n",
            "        [16, 37,  1, 19, 30, 17, 37, 10],\n",
            "        [59, 54,  1, 58, 46, 43,  1, 51],\n",
            "        [46, 52, 43, 57, 57,  6,  1, 54],\n",
            "        [10,  0, 61, 46, 63,  6,  1, 58],\n",
            "        [53, 47, 52,  5, 42,  0, 14, 63],\n",
            "        [ 8,  0,  0, 19, 24, 27, 33, 15],\n",
            "        [39, 58,  1, 24, 43, 61, 47, 57],\n",
            "        [56, 43,  2,  0,  0, 14, 33, 15],\n",
            "        [43, 50, 41, 53, 51, 43,  6,  1],\n",
            "        [34, 27, 24, 21, 27, 10,  0, 32],\n",
            "        [ 1, 40, 50, 47, 52, 42,  1, 44],\n",
            "        [46, 43, 56,  1, 57, 58, 39, 63],\n",
            "        [39, 50, 50,  1, 39, 50, 43,  8],\n",
            "        [58, 41, 46,  1, 57, 46, 56, 47],\n",
            "        [51,  1, 63, 53, 59, 56, 57,  1],\n",
            "        [58, 46, 43,  1, 57, 46, 43, 54],\n",
            "        [ 1, 53, 56,  1, 61, 39, 56,  8],\n",
            "        [56, 47, 49, 43, 57, 58,  1, 51],\n",
            "        [51, 43, 56, 41, 43, 52, 39, 56],\n",
            "        [15, 17, 10,  0, 13,  1, 50, 47],\n",
            "        [ 1, 21,  1, 61, 53, 59, 50, 42],\n",
            "        [43,  1, 43, 63, 43, 57,  8,  1],\n",
            "        [39, 52, 42,  1, 41, 53, 59, 50]])\n",
            "---------\n",
            "when context is: [53] target is: 1\n",
            "when context is: [53, 1] target is: 40\n",
            "when context is: [53, 1, 40] target is: 43\n",
            "when context is: [53, 1, 40, 43] target is: 1\n",
            "when context is: [53, 1, 40, 43, 1] target is: 58\n",
            "when context is: [53, 1, 40, 43, 1, 58] target is: 39\n",
            "when context is: [53, 1, 40, 43, 1, 58, 39] target is: 50\n",
            "when context is: [53, 1, 40, 43, 1, 58, 39, 50] target is: 49\n",
            "when context is: [1] target is: 42\n",
            "when context is: [1, 42] target is: 53\n",
            "when context is: [1, 42, 53] target is: 1\n",
            "when context is: [1, 42, 53, 1] target is: 52\n",
            "when context is: [1, 42, 53, 1, 52] target is: 53\n",
            "when context is: [1, 42, 53, 1, 52, 53] target is: 58\n",
            "when context is: [1, 42, 53, 1, 52, 53, 58] target is: 1\n",
            "when context is: [1, 42, 53, 1, 52, 53, 58, 1] target is: 46\n",
            "when context is: [47] target is: 58\n",
            "when context is: [47, 58] target is: 1\n",
            "when context is: [47, 58, 1] target is: 47\n",
            "when context is: [47, 58, 1, 47] target is: 57\n",
            "when context is: [47, 58, 1, 47, 57] target is: 1\n",
            "when context is: [47, 58, 1, 47, 57, 1] target is: 52\n",
            "when context is: [47, 58, 1, 47, 57, 1, 52] target is: 53\n",
            "when context is: [47, 58, 1, 47, 57, 1, 52, 53] target is: 61\n",
            "when context is: [25] target is: 13\n",
            "when context is: [25, 13] target is: 30\n",
            "when context is: [25, 13, 30] target is: 19\n",
            "when context is: [25, 13, 30, 19] target is: 13\n",
            "when context is: [25, 13, 30, 19, 13] target is: 30\n",
            "when context is: [25, 13, 30, 19, 13, 30] target is: 17\n",
            "when context is: [25, 13, 30, 19, 13, 30, 17] target is: 32\n",
            "when context is: [25, 13, 30, 19, 13, 30, 17, 32] target is: 10\n",
            "when context is: [43] target is: 1\n",
            "when context is: [43, 1] target is: 39\n",
            "when context is: [43, 1, 39] target is: 58\n",
            "when context is: [43, 1, 39, 58] target is: 1\n",
            "when context is: [43, 1, 39, 58, 1] target is: 58\n",
            "when context is: [43, 1, 39, 58, 1, 58] target is: 46\n",
            "when context is: [43, 1, 39, 58, 1, 58, 46] target is: 63\n",
            "when context is: [43, 1, 39, 58, 1, 58, 46, 63] target is: 1\n",
            "when context is: [46] target is: 47\n",
            "when context is: [46, 47] target is: 57\n",
            "when context is: [46, 47, 57] target is: 1\n",
            "when context is: [46, 47, 57, 1] target is: 46\n",
            "when context is: [46, 47, 57, 1, 46] target is: 53\n",
            "when context is: [46, 47, 57, 1, 46, 53] target is: 50\n",
            "when context is: [46, 47, 57, 1, 46, 53, 50] target is: 63\n",
            "when context is: [46, 47, 57, 1, 46, 53, 50, 63] target is: 1\n",
            "when context is: [0] target is: 26\n",
            "when context is: [0, 26] target is: 53\n",
            "when context is: [0, 26, 53] target is: 61\n",
            "when context is: [0, 26, 53, 61] target is: 1\n",
            "when context is: [0, 26, 53, 61, 1] target is: 57\n",
            "when context is: [0, 26, 53, 61, 1, 57] target is: 61\n",
            "when context is: [0, 26, 53, 61, 1, 57, 61] target is: 39\n",
            "when context is: [0, 26, 53, 61, 1, 57, 61, 39] target is: 50\n",
            "when context is: [1] target is: 52\n",
            "when context is: [1, 52] target is: 39\n",
            "when context is: [1, 52, 39] target is: 51\n",
            "when context is: [1, 52, 39, 51] target is: 43\n",
            "when context is: [1, 52, 39, 51, 43] target is: 1\n",
            "when context is: [1, 52, 39, 51, 43, 1] target is: 40\n",
            "when context is: [1, 52, 39, 51, 43, 1, 40] target is: 43\n",
            "when context is: [1, 52, 39, 51, 43, 1, 40, 43] target is: 1\n",
            "when context is: [0] target is: 25\n",
            "when context is: [0, 25] target is: 17\n",
            "when context is: [0, 25, 17] target is: 26\n",
            "when context is: [0, 25, 17, 26] target is: 17\n",
            "when context is: [0, 25, 17, 26, 17] target is: 26\n",
            "when context is: [0, 25, 17, 26, 17, 26] target is: 21\n",
            "when context is: [0, 25, 17, 26, 17, 26, 21] target is: 33\n",
            "when context is: [0, 25, 17, 26, 17, 26, 21, 33] target is: 31\n",
            "when context is: [13] target is: 16\n",
            "when context is: [13, 16] target is: 37\n",
            "when context is: [13, 16, 37] target is: 1\n",
            "when context is: [13, 16, 37, 1] target is: 19\n",
            "when context is: [13, 16, 37, 1, 19] target is: 30\n",
            "when context is: [13, 16, 37, 1, 19, 30] target is: 17\n",
            "when context is: [13, 16, 37, 1, 19, 30, 17] target is: 37\n",
            "when context is: [13, 16, 37, 1, 19, 30, 17, 37] target is: 10\n",
            "when context is: [1] target is: 59\n",
            "when context is: [1, 59] target is: 54\n",
            "when context is: [1, 59, 54] target is: 1\n",
            "when context is: [1, 59, 54, 1] target is: 58\n",
            "when context is: [1, 59, 54, 1, 58] target is: 46\n",
            "when context is: [1, 59, 54, 1, 58, 46] target is: 43\n",
            "when context is: [1, 59, 54, 1, 58, 46, 43] target is: 1\n",
            "when context is: [1, 59, 54, 1, 58, 46, 43, 1] target is: 51\n",
            "when context is: [45] target is: 46\n",
            "when context is: [45, 46] target is: 52\n",
            "when context is: [45, 46, 52] target is: 43\n",
            "when context is: [45, 46, 52, 43] target is: 57\n",
            "when context is: [45, 46, 52, 43, 57] target is: 57\n",
            "when context is: [45, 46, 52, 43, 57, 57] target is: 6\n",
            "when context is: [45, 46, 52, 43, 57, 57, 6] target is: 1\n",
            "when context is: [45, 46, 52, 43, 57, 57, 6, 1] target is: 54\n",
            "when context is: [53] target is: 10\n",
            "when context is: [53, 10] target is: 0\n",
            "when context is: [53, 10, 0] target is: 61\n",
            "when context is: [53, 10, 0, 61] target is: 46\n",
            "when context is: [53, 10, 0, 61, 46] target is: 63\n",
            "when context is: [53, 10, 0, 61, 46, 63] target is: 6\n",
            "when context is: [53, 10, 0, 61, 46, 63, 6] target is: 1\n",
            "when context is: [53, 10, 0, 61, 46, 63, 6, 1] target is: 58\n",
            "when context is: [48] target is: 53\n",
            "when context is: [48, 53] target is: 47\n",
            "when context is: [48, 53, 47] target is: 52\n",
            "when context is: [48, 53, 47, 52] target is: 5\n",
            "when context is: [48, 53, 47, 52, 5] target is: 42\n",
            "when context is: [48, 53, 47, 52, 5, 42] target is: 0\n",
            "when context is: [48, 53, 47, 52, 5, 42, 0] target is: 14\n",
            "when context is: [48, 53, 47, 52, 5, 42, 0, 14] target is: 63\n",
            "when context is: [42] target is: 8\n",
            "when context is: [42, 8] target is: 0\n",
            "when context is: [42, 8, 0] target is: 0\n",
            "when context is: [42, 8, 0, 0] target is: 19\n",
            "when context is: [42, 8, 0, 0, 19] target is: 24\n",
            "when context is: [42, 8, 0, 0, 19, 24] target is: 27\n",
            "when context is: [42, 8, 0, 0, 19, 24, 27] target is: 33\n",
            "when context is: [42, 8, 0, 0, 19, 24, 27, 33] target is: 15\n",
            "when context is: [46] target is: 39\n",
            "when context is: [46, 39] target is: 58\n",
            "when context is: [46, 39, 58] target is: 1\n",
            "when context is: [46, 39, 58, 1] target is: 24\n",
            "when context is: [46, 39, 58, 1, 24] target is: 43\n",
            "when context is: [46, 39, 58, 1, 24, 43] target is: 61\n",
            "when context is: [46, 39, 58, 1, 24, 43, 61] target is: 47\n",
            "when context is: [46, 39, 58, 1, 24, 43, 61, 47] target is: 57\n",
            "when context is: [43] target is: 56\n",
            "when context is: [43, 56] target is: 43\n",
            "when context is: [43, 56, 43] target is: 2\n",
            "when context is: [43, 56, 43, 2] target is: 0\n",
            "when context is: [43, 56, 43, 2, 0] target is: 0\n",
            "when context is: [43, 56, 43, 2, 0, 0] target is: 14\n",
            "when context is: [43, 56, 43, 2, 0, 0, 14] target is: 33\n",
            "when context is: [43, 56, 43, 2, 0, 0, 14, 33] target is: 15\n",
            "when context is: [35] target is: 43\n",
            "when context is: [35, 43] target is: 50\n",
            "when context is: [35, 43, 50] target is: 41\n",
            "when context is: [35, 43, 50, 41] target is: 53\n",
            "when context is: [35, 43, 50, 41, 53] target is: 51\n",
            "when context is: [35, 43, 50, 41, 53, 51] target is: 43\n",
            "when context is: [35, 43, 50, 41, 53, 51, 43] target is: 6\n",
            "when context is: [35, 43, 50, 41, 53, 51, 43, 6] target is: 1\n",
            "when context is: [26] target is: 34\n",
            "when context is: [26, 34] target is: 27\n",
            "when context is: [26, 34, 27] target is: 24\n",
            "when context is: [26, 34, 27, 24] target is: 21\n",
            "when context is: [26, 34, 27, 24, 21] target is: 27\n",
            "when context is: [26, 34, 27, 24, 21, 27] target is: 10\n",
            "when context is: [26, 34, 27, 24, 21, 27, 10] target is: 0\n",
            "when context is: [26, 34, 27, 24, 21, 27, 10, 0] target is: 32\n",
            "when context is: [57] target is: 1\n",
            "when context is: [57, 1] target is: 40\n",
            "when context is: [57, 1, 40] target is: 50\n",
            "when context is: [57, 1, 40, 50] target is: 47\n",
            "when context is: [57, 1, 40, 50, 47] target is: 52\n",
            "when context is: [57, 1, 40, 50, 47, 52] target is: 42\n",
            "when context is: [57, 1, 40, 50, 47, 52, 42] target is: 1\n",
            "when context is: [57, 1, 40, 50, 47, 52, 42, 1] target is: 44\n",
            "when context is: [58] target is: 46\n",
            "when context is: [58, 46] target is: 43\n",
            "when context is: [58, 46, 43] target is: 56\n",
            "when context is: [58, 46, 43, 56] target is: 1\n",
            "when context is: [58, 46, 43, 56, 1] target is: 57\n",
            "when context is: [58, 46, 43, 56, 1, 57] target is: 58\n",
            "when context is: [58, 46, 43, 56, 1, 57, 58] target is: 39\n",
            "when context is: [58, 46, 43, 56, 1, 57, 58, 39] target is: 63\n",
            "when context is: [51] target is: 39\n",
            "when context is: [51, 39] target is: 50\n",
            "when context is: [51, 39, 50] target is: 50\n",
            "when context is: [51, 39, 50, 50] target is: 1\n",
            "when context is: [51, 39, 50, 50, 1] target is: 39\n",
            "when context is: [51, 39, 50, 50, 1, 39] target is: 50\n",
            "when context is: [51, 39, 50, 50, 1, 39, 50] target is: 43\n",
            "when context is: [51, 39, 50, 50, 1, 39, 50, 43] target is: 8\n",
            "when context is: [43] target is: 58\n",
            "when context is: [43, 58] target is: 41\n",
            "when context is: [43, 58, 41] target is: 46\n",
            "when context is: [43, 58, 41, 46] target is: 1\n",
            "when context is: [43, 58, 41, 46, 1] target is: 57\n",
            "when context is: [43, 58, 41, 46, 1, 57] target is: 46\n",
            "when context is: [43, 58, 41, 46, 1, 57, 46] target is: 56\n",
            "when context is: [43, 58, 41, 46, 1, 57, 46, 56] target is: 47\n",
            "when context is: [39] target is: 51\n",
            "when context is: [39, 51] target is: 1\n",
            "when context is: [39, 51, 1] target is: 63\n",
            "when context is: [39, 51, 1, 63] target is: 53\n",
            "when context is: [39, 51, 1, 63, 53] target is: 59\n",
            "when context is: [39, 51, 1, 63, 53, 59] target is: 56\n",
            "when context is: [39, 51, 1, 63, 53, 59, 56] target is: 57\n",
            "when context is: [39, 51, 1, 63, 53, 59, 56, 57] target is: 1\n",
            "when context is: [1] target is: 58\n",
            "when context is: [1, 58] target is: 46\n",
            "when context is: [1, 58, 46] target is: 43\n",
            "when context is: [1, 58, 46, 43] target is: 1\n",
            "when context is: [1, 58, 46, 43, 1] target is: 57\n",
            "when context is: [1, 58, 46, 43, 1, 57] target is: 46\n",
            "when context is: [1, 58, 46, 43, 1, 57, 46] target is: 43\n",
            "when context is: [1, 58, 46, 43, 1, 57, 46, 43] target is: 54\n",
            "when context is: [43] target is: 1\n",
            "when context is: [43, 1] target is: 53\n",
            "when context is: [43, 1, 53] target is: 56\n",
            "when context is: [43, 1, 53, 56] target is: 1\n",
            "when context is: [43, 1, 53, 56, 1] target is: 61\n",
            "when context is: [43, 1, 53, 56, 1, 61] target is: 39\n",
            "when context is: [43, 1, 53, 56, 1, 61, 39] target is: 56\n",
            "when context is: [43, 1, 53, 56, 1, 61, 39, 56] target is: 8\n",
            "when context is: [58] target is: 56\n",
            "when context is: [58, 56] target is: 47\n",
            "when context is: [58, 56, 47] target is: 49\n",
            "when context is: [58, 56, 47, 49] target is: 43\n",
            "when context is: [58, 56, 47, 49, 43] target is: 57\n",
            "when context is: [58, 56, 47, 49, 43, 57] target is: 58\n",
            "when context is: [58, 56, 47, 49, 43, 57, 58] target is: 1\n",
            "when context is: [58, 56, 47, 49, 43, 57, 58, 1] target is: 51\n",
            "when context is: [1] target is: 51\n",
            "when context is: [1, 51] target is: 43\n",
            "when context is: [1, 51, 43] target is: 56\n",
            "when context is: [1, 51, 43, 56] target is: 41\n",
            "when context is: [1, 51, 43, 56, 41] target is: 43\n",
            "when context is: [1, 51, 43, 56, 41, 43] target is: 52\n",
            "when context is: [1, 51, 43, 56, 41, 43, 52] target is: 39\n",
            "when context is: [1, 51, 43, 56, 41, 43, 52, 39] target is: 56\n",
            "when context is: [26] target is: 15\n",
            "when context is: [26, 15] target is: 17\n",
            "when context is: [26, 15, 17] target is: 10\n",
            "when context is: [26, 15, 17, 10] target is: 0\n",
            "when context is: [26, 15, 17, 10, 0] target is: 13\n",
            "when context is: [26, 15, 17, 10, 0, 13] target is: 1\n",
            "when context is: [26, 15, 17, 10, 0, 13, 1] target is: 50\n",
            "when context is: [26, 15, 17, 10, 0, 13, 1, 50] target is: 47\n",
            "when context is: [58] target is: 1\n",
            "when context is: [58, 1] target is: 21\n",
            "when context is: [58, 1, 21] target is: 1\n",
            "when context is: [58, 1, 21, 1] target is: 61\n",
            "when context is: [58, 1, 21, 1, 61] target is: 53\n",
            "when context is: [58, 1, 21, 1, 61, 53] target is: 59\n",
            "when context is: [58, 1, 21, 1, 61, 53, 59] target is: 50\n",
            "when context is: [58, 1, 21, 1, 61, 53, 59, 50] target is: 42\n",
            "when context is: [52] target is: 43\n",
            "when context is: [52, 43] target is: 1\n",
            "when context is: [52, 43, 1] target is: 43\n",
            "when context is: [52, 43, 1, 43] target is: 63\n",
            "when context is: [52, 43, 1, 43, 63] target is: 43\n",
            "when context is: [52, 43, 1, 43, 63, 43] target is: 57\n",
            "when context is: [52, 43, 1, 43, 63, 43, 57] target is: 8\n",
            "when context is: [52, 43, 1, 43, 63, 43, 57, 8] target is: 1\n",
            "when context is: [1] target is: 39\n",
            "when context is: [1, 39] target is: 52\n",
            "when context is: [1, 39, 52] target is: 42\n",
            "when context is: [1, 39, 52, 42] target is: 1\n",
            "when context is: [1, 39, 52, 42, 1] target is: 41\n",
            "when context is: [1, 39, 52, 42, 1, 41] target is: 53\n",
            "when context is: [1, 39, 52, 42, 1, 41, 53] target is: 59\n",
            "when context is: [1, 39, 52, 42, 1, 41, 53, 59] target is: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    # compute the attention scores ('affinities)\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) ---> (B, T, T) , used scaled attention here\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) , this is part of decoder so does not communicate with past\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    # perform the weighted aggregation of values\n",
        "    v = self.value(x) # (B, T, C)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
        "    return out"
      ],
      "metadata": {
        "id": "-cwnxNTblqHO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1033)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BigramLanguageModel, self).__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "    self.sa_head = Head(n_embed)\n",
        "    self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "  def forward(self, idx, target=None):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    # idx and targets are both (B,T) tensors of integer\n",
        "    token_embed = self.token_embedding_table(idx) # (B,T,C) where C is n_embed\n",
        "    pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
        "    X = token_embed + pos_embed # (B, T, C)\n",
        "    X = self.sa_head(X) # apply one head of self-attention (B, T, C)\n",
        "    logits = self.lm_head(X) # (B, T, Vocab_size)\n",
        "\n",
        "    if target is not None:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      target = target.view(-1) # or target.view(B*T)\n",
        "      loss = F.cross_entropy(logits, target)\n",
        "\n",
        "    else:\n",
        "      loss = None\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_char):\n",
        "    #idx is (B, T) array of indices in current context\n",
        "    for _ in range(max_new_char):\n",
        "      # print(idx.shape)\n",
        "      # print(idx)\n",
        "      # crop idx to the last block_size tokens\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "      # print(idx_cond)\n",
        "      # get the predictions\n",
        "      logits, loss = self(idx_cond)\n",
        "      # Focus only on last time step\n",
        "      logits = logits[:, -1, :] # becomes [B, C]\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B,C)\n",
        "      # sample from distribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
        "      # append sampled index to running index\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (b , T+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "logits, loss = m(xb, yb)\n",
        "# print(logits.shape)\n",
        "# print(loss)\n",
        "# start_token = torch.zeros((1,1), dtype=torch.long)\n",
        "# print(decode(m.generate(start_token, 100)[0].tolist()))"
      ],
      "metadata": {
        "id": "dCBWT27Ve-ne"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Optimizer\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr = lr_rate)"
      ],
      "metadata": {
        "id": "GfcK2gMlhpKB"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      xb, yb = get_batch(split)\n",
        "      logits, loss = m(xb, yb)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "xZAU4HsLG2qk"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for steps in range(max_iters):\n",
        "\n",
        "  if steps % eval_interval == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {steps}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_stjVIvswLJ",
        "outputId": "d77f689f-3a5c-44db-d5c6-90704e127d6d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1883, val loss 4.1867\n",
            "step 500: train loss 2.6732, val loss 2.6848\n",
            "step 1000: train loss 2.5387, val loss 2.5329\n",
            "step 1500: train loss 2.4780, val loss 2.4882\n",
            "step 2000: train loss 2.4472, val loss 2.4581\n",
            "step 2500: train loss 2.4245, val loss 2.4410\n",
            "step 3000: train loss 2.4110, val loss 2.4271\n",
            "step 3500: train loss 2.4087, val loss 2.4207\n",
            "step 4000: train loss 2.3954, val loss 2.4082\n",
            "step 4500: train loss 2.3833, val loss 2.4001\n",
            "2.3512332439422607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(start_token, 1000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoMlsmthvfuV",
        "outputId": "d3839d57-0410-4a98-d911-1e93a673aa21"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Firsourd manat.\n",
            "Cin ed tex'ctigese om hemeyove then yoru Ad lt st kit\n",
            "fou satnean sif, tllold or\n",
            "r,e bre, thet is m'ss hect lthe my ind ove he scade ned oligucer cre wollo cer vend, hald herp cinmak foouengo fenert-olis of ed nwely spal 'mt'dongwh\n",
            "Acasingthe hat utalli, me:\n",
            "Ath I WARowus ascage ld nde\n",
            "As oten,\n",
            "Councare lomeler mor deras ys\n",
            "rey gf wine,\n",
            "'Bt llepf, habere:\n",
            "Wher tri'encat thout bollel com it orndimul chit werberowsus lis hin wamer outo ow, chemy cker-'ser, blary mene Rnout yorear 'bando shayon ul avis fovile me bep-en hat oincexwccour lod ured bes, yavewe hen te\n",
            "wat hingoange sy:\n",
            "Thearn cais, fay, sme indyorfomandent-hanad ciadatenshe ayomont pan os stfand st.\n",
            "Ne Ined.\n",
            "\n",
            "Whed se hey mere mif, our beme ne hat pis ond.\n",
            "\n",
            "ON!\n",
            "\n",
            "\n",
            "CABaty cegur ve ors as? ige wopr Man kin\n",
            "See dolo wtho wat upersster\n",
            "Whes Pe\n",
            "PA-tievens yy laewedemins din's st hintoru, ble mond hat dhe\n",
            "R GCAISheit\n",
            "Thowndourtoh andr ay moduciostt to ame tinge nor pay blud ise cos te!\n",
            "\n",
            "MAs wik wandold, sust?\n",
            "Nse nder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtCxdNYlv7te"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "66DW_pgOVlHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example\n",
        "\n",
        "torch.manual_seed(1033)\n",
        "B, T, C = 4, 8, 2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR8UI3hbVqgn",
        "outputId": "a35b067f-1a80-4da5-b9e2-c88e2e64df3a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want x[b,t] = mean_{i <= t} x[b, i]\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    prev = x[b,:t+1] # (T, C)\n",
        "    xbow[b,t] = torch.mean(prev, 0) # mean over T"
      ],
      "metadata": {
        "id": "qK7y2gGqWIbb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Approve 2\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B,T,C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLgtJ15_2hmF",
        "outputId": "7b9da15f-f810-453f-df4b-06325a47fa51"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 3\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros(T,T)\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x"
      ],
      "metadata": {
        "id": "yvTwvSaj3eeN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 4 self-attention\n",
        "torch.manual_seed(1033)\n",
        "B,T,C = 4, 8, 32 # Batch, timesteps, channels\n",
        "x = torch.randn(B,T,C)\n",
        "# single head attention\n",
        "head_size = 16\n",
        "key = torch.nn.Linear(C,head_size, bias = False)\n",
        "query = torch.nn.Linear(C, head_size, bias = False)\n",
        "value = torch.nn.Linear(C, head_size, bias = False)\n",
        "k = key(x) # (B, T, head_size)\n",
        "q = query(x) # (B, T, head_size)\n",
        "#v = key(x) # (B, T, head_size)\n",
        "\n",
        "wei = q @ k.transpose(-2,-1) # (B,T, 16) @ (B, 16, T) ----> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros(T,T)\n",
        "wei = wei.masked_fill(tril==0, float('-inf')) # this line prevents tokens to see future token in sequence and should be used in decoder part\n",
        "# we can comments above line in encoder part so that token can interact with each other.\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWLKQhnhDsmq",
        "outputId": "c6536732-85a5-4888-abf2-0fde6744674f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VorFJ7t1k8zl",
        "outputId": "1ad161a3-2ad0-4c2a-e571-dd591f3024d8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.7859, 0.2141, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.9380, 0.0449, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1615, 0.0673, 0.0268, 0.7443, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1607, 0.1225, 0.5069, 0.0831, 0.1268, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1984, 0.0583, 0.0603, 0.4056, 0.0650, 0.2123, 0.0000, 0.0000],\n",
              "        [0.0640, 0.1126, 0.0121, 0.1895, 0.0254, 0.3290, 0.2674, 0.0000],\n",
              "        [0.5500, 0.0317, 0.0150, 0.3041, 0.0131, 0.0272, 0.0273, 0.0316]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfUDAh5GX3gg",
        "outputId": "052d4eb6-49c6-44f5-f4ca-fe1fe7f65885"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4115,  1.2941],\n",
              "        [-0.1356,  0.5413],\n",
              "        [ 0.9311, -0.5061],\n",
              "        [ 0.7235,  0.9506],\n",
              "        [ 1.3993,  0.4271],\n",
              "        [-0.9396,  0.1607],\n",
              "        [-0.1828,  1.3827],\n",
              "        [-1.3406, -0.2682]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Bxfl47X12K",
        "outputId": "1c6845f1-86d9-4377-b717-f364d715d328"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4115,  1.2941],\n",
              "        [-0.2735,  0.9177],\n",
              "        [ 0.1280,  0.4431],\n",
              "        [ 0.2769,  0.5700],\n",
              "        [ 0.5013,  0.5414],\n",
              "        [ 0.2612,  0.4780],\n",
              "        [ 0.1978,  0.6072],\n",
              "        [ 0.0055,  0.4978]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(3,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-ctQhcS1hzm",
        "outputId": "3b6e3cfb-624a-456c-c981-b0d411ae091b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.manual_seed(1033)\n",
        "a = torch.tril(torch.ones(3,3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10, (3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('b=')\n",
        "print(b)\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T1unAkoX90x",
        "outputId": "99dee4ed-dc7b-431b-b58a-534e978facd8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "b=\n",
            "tensor([[8., 5.],\n",
            "        [0., 7.],\n",
            "        [7., 7.]])\n",
            "c=\n",
            "tensor([[8.0000, 5.0000],\n",
            "        [4.0000, 6.0000],\n",
            "        [5.0000, 6.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFi3mT371Srz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}