{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvp1OL31jC6S7LMSIiY/Iw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarsh415/gpt/blob/main/gpt_Block_FeedForward_multiHead_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3feIKpsj4zP",
        "outputId": "1aebc4ef-8be9-43f1-9de1-ecec0edaf8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-22 17:58:06--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.4’\n",
            "\n",
            "\rinput.txt.4           0%[                    ]       0  --.-KB/s               \rinput.txt.4         100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-22 17:58:06 (30.6 MB/s) - ‘input.txt.4’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "hrOTjzPlkQZC"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVgczUeMkjZQ",
        "outputId": "91d76f1f-8c48-417b-c145-92c3a495b2d2"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AeiyqN3kxfi",
        "outputId": "1a527f68-5d67-45dc-d46e-c61f4ce6e374"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all unique characters that occurs in text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNUqoBV_k5P8",
        "outputId": "a114f47c-7863-411f-c5e9-bae21f5c9aa8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping from characters to integers\n",
        "stoi = {ch:i for i, ch in enumerate(chars)}\n",
        "itos = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: takes a string, returns sequence of intgers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: takes list of integers, outputs string\n",
        "\n",
        "print(encode('hii there'))\n",
        "print(decode(encode('hii there')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4iSKzylUWt",
        "outputId": "f29ad12c-09ba-49f5-bcd0-a50145084876"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Hncx_kFsly_f"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32 # how many independent sequences will process in parallel\n",
        "block_size=8 # what is the maximum context length of predictions?\n",
        "n_embed = 32\n",
        "lr_rate = 1e-3\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "max_iters = 5000"
      ],
      "metadata": {
        "id": "wABAcoSvp90f"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V7tdNHflVan",
        "outputId": "c04e59c9-19c0-4cfe-d6d0-afe8abcac5e5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's split dataset into train and validation set\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "GYih96aap3KU"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:block_size + 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZXpoSxqQLd",
        "outputId": "87b04e84-9425-4975-c8e7-eaedf8573540"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when context is: {context} target is: {target}\")"
      ],
      "metadata": {
        "id": "LmKrlNZ7qvBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a29e471-cdc3-473c-ad9a-c79198a76884"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when context is: tensor([18]) target is: 47\n",
            "when context is: tensor([18, 47]) target is: 56\n",
            "when context is: tensor([18, 47, 56]) target is: 57\n",
            "when context is: tensor([18, 47, 56, 57]) target is: 58\n",
            "when context is: tensor([18, 47, 56, 57, 58]) target is: 1\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1]) target is: 15\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1, 15]) target is: 47\n",
            "when context is: tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1023)\n",
        "def get_batch(split):\n",
        "  data = train_data if split=='train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('target')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('---------')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension\n",
        "    context = xb[b, :t+1]\n",
        "    target = yb[b, t]\n",
        "    print(f\"when context is: {context.tolist()} target is: {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvBQggSPe7Uw",
        "outputId": "e4f2d857-0d31-4de9-8170-3bd05f342bbc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "torch.Size([32, 8])\n",
            "tensor([[53,  1, 40, 43,  1, 58, 39, 50],\n",
            "        [ 1, 42, 53,  1, 52, 53, 58,  1],\n",
            "        [47, 58,  1, 47, 57,  1, 52, 53],\n",
            "        [25, 13, 30, 19, 13, 30, 17, 32],\n",
            "        [43,  1, 39, 58,  1, 58, 46, 63],\n",
            "        [46, 47, 57,  1, 46, 53, 50, 63],\n",
            "        [ 0, 26, 53, 61,  1, 57, 61, 39],\n",
            "        [ 1, 52, 39, 51, 43,  1, 40, 43],\n",
            "        [ 0, 25, 17, 26, 17, 26, 21, 33],\n",
            "        [13, 16, 37,  1, 19, 30, 17, 37],\n",
            "        [ 1, 59, 54,  1, 58, 46, 43,  1],\n",
            "        [45, 46, 52, 43, 57, 57,  6,  1],\n",
            "        [53, 10,  0, 61, 46, 63,  6,  1],\n",
            "        [48, 53, 47, 52,  5, 42,  0, 14],\n",
            "        [42,  8,  0,  0, 19, 24, 27, 33],\n",
            "        [46, 39, 58,  1, 24, 43, 61, 47],\n",
            "        [43, 56, 43,  2,  0,  0, 14, 33],\n",
            "        [35, 43, 50, 41, 53, 51, 43,  6],\n",
            "        [26, 34, 27, 24, 21, 27, 10,  0],\n",
            "        [57,  1, 40, 50, 47, 52, 42,  1],\n",
            "        [58, 46, 43, 56,  1, 57, 58, 39],\n",
            "        [51, 39, 50, 50,  1, 39, 50, 43],\n",
            "        [43, 58, 41, 46,  1, 57, 46, 56],\n",
            "        [39, 51,  1, 63, 53, 59, 56, 57],\n",
            "        [ 1, 58, 46, 43,  1, 57, 46, 43],\n",
            "        [43,  1, 53, 56,  1, 61, 39, 56],\n",
            "        [58, 56, 47, 49, 43, 57, 58,  1],\n",
            "        [ 1, 51, 43, 56, 41, 43, 52, 39],\n",
            "        [26, 15, 17, 10,  0, 13,  1, 50],\n",
            "        [58,  1, 21,  1, 61, 53, 59, 50],\n",
            "        [52, 43,  1, 43, 63, 43, 57,  8],\n",
            "        [ 1, 39, 52, 42,  1, 41, 53, 59]])\n",
            "target\n",
            "torch.Size([32, 8])\n",
            "tensor([[ 1, 40, 43,  1, 58, 39, 50, 49],\n",
            "        [42, 53,  1, 52, 53, 58,  1, 46],\n",
            "        [58,  1, 47, 57,  1, 52, 53, 61],\n",
            "        [13, 30, 19, 13, 30, 17, 32, 10],\n",
            "        [ 1, 39, 58,  1, 58, 46, 63,  1],\n",
            "        [47, 57,  1, 46, 53, 50, 63,  1],\n",
            "        [26, 53, 61,  1, 57, 61, 39, 50],\n",
            "        [52, 39, 51, 43,  1, 40, 43,  1],\n",
            "        [25, 17, 26, 17, 26, 21, 33, 31],\n",
            "        [16, 37,  1, 19, 30, 17, 37, 10],\n",
            "        [59, 54,  1, 58, 46, 43,  1, 51],\n",
            "        [46, 52, 43, 57, 57,  6,  1, 54],\n",
            "        [10,  0, 61, 46, 63,  6,  1, 58],\n",
            "        [53, 47, 52,  5, 42,  0, 14, 63],\n",
            "        [ 8,  0,  0, 19, 24, 27, 33, 15],\n",
            "        [39, 58,  1, 24, 43, 61, 47, 57],\n",
            "        [56, 43,  2,  0,  0, 14, 33, 15],\n",
            "        [43, 50, 41, 53, 51, 43,  6,  1],\n",
            "        [34, 27, 24, 21, 27, 10,  0, 32],\n",
            "        [ 1, 40, 50, 47, 52, 42,  1, 44],\n",
            "        [46, 43, 56,  1, 57, 58, 39, 63],\n",
            "        [39, 50, 50,  1, 39, 50, 43,  8],\n",
            "        [58, 41, 46,  1, 57, 46, 56, 47],\n",
            "        [51,  1, 63, 53, 59, 56, 57,  1],\n",
            "        [58, 46, 43,  1, 57, 46, 43, 54],\n",
            "        [ 1, 53, 56,  1, 61, 39, 56,  8],\n",
            "        [56, 47, 49, 43, 57, 58,  1, 51],\n",
            "        [51, 43, 56, 41, 43, 52, 39, 56],\n",
            "        [15, 17, 10,  0, 13,  1, 50, 47],\n",
            "        [ 1, 21,  1, 61, 53, 59, 50, 42],\n",
            "        [43,  1, 43, 63, 43, 57,  8,  1],\n",
            "        [39, 52, 42,  1, 41, 53, 59, 50]])\n",
            "---------\n",
            "when context is: [53] target is: 1\n",
            "when context is: [53, 1] target is: 40\n",
            "when context is: [53, 1, 40] target is: 43\n",
            "when context is: [53, 1, 40, 43] target is: 1\n",
            "when context is: [53, 1, 40, 43, 1] target is: 58\n",
            "when context is: [53, 1, 40, 43, 1, 58] target is: 39\n",
            "when context is: [53, 1, 40, 43, 1, 58, 39] target is: 50\n",
            "when context is: [53, 1, 40, 43, 1, 58, 39, 50] target is: 49\n",
            "when context is: [1] target is: 42\n",
            "when context is: [1, 42] target is: 53\n",
            "when context is: [1, 42, 53] target is: 1\n",
            "when context is: [1, 42, 53, 1] target is: 52\n",
            "when context is: [1, 42, 53, 1, 52] target is: 53\n",
            "when context is: [1, 42, 53, 1, 52, 53] target is: 58\n",
            "when context is: [1, 42, 53, 1, 52, 53, 58] target is: 1\n",
            "when context is: [1, 42, 53, 1, 52, 53, 58, 1] target is: 46\n",
            "when context is: [47] target is: 58\n",
            "when context is: [47, 58] target is: 1\n",
            "when context is: [47, 58, 1] target is: 47\n",
            "when context is: [47, 58, 1, 47] target is: 57\n",
            "when context is: [47, 58, 1, 47, 57] target is: 1\n",
            "when context is: [47, 58, 1, 47, 57, 1] target is: 52\n",
            "when context is: [47, 58, 1, 47, 57, 1, 52] target is: 53\n",
            "when context is: [47, 58, 1, 47, 57, 1, 52, 53] target is: 61\n",
            "when context is: [25] target is: 13\n",
            "when context is: [25, 13] target is: 30\n",
            "when context is: [25, 13, 30] target is: 19\n",
            "when context is: [25, 13, 30, 19] target is: 13\n",
            "when context is: [25, 13, 30, 19, 13] target is: 30\n",
            "when context is: [25, 13, 30, 19, 13, 30] target is: 17\n",
            "when context is: [25, 13, 30, 19, 13, 30, 17] target is: 32\n",
            "when context is: [25, 13, 30, 19, 13, 30, 17, 32] target is: 10\n",
            "when context is: [43] target is: 1\n",
            "when context is: [43, 1] target is: 39\n",
            "when context is: [43, 1, 39] target is: 58\n",
            "when context is: [43, 1, 39, 58] target is: 1\n",
            "when context is: [43, 1, 39, 58, 1] target is: 58\n",
            "when context is: [43, 1, 39, 58, 1, 58] target is: 46\n",
            "when context is: [43, 1, 39, 58, 1, 58, 46] target is: 63\n",
            "when context is: [43, 1, 39, 58, 1, 58, 46, 63] target is: 1\n",
            "when context is: [46] target is: 47\n",
            "when context is: [46, 47] target is: 57\n",
            "when context is: [46, 47, 57] target is: 1\n",
            "when context is: [46, 47, 57, 1] target is: 46\n",
            "when context is: [46, 47, 57, 1, 46] target is: 53\n",
            "when context is: [46, 47, 57, 1, 46, 53] target is: 50\n",
            "when context is: [46, 47, 57, 1, 46, 53, 50] target is: 63\n",
            "when context is: [46, 47, 57, 1, 46, 53, 50, 63] target is: 1\n",
            "when context is: [0] target is: 26\n",
            "when context is: [0, 26] target is: 53\n",
            "when context is: [0, 26, 53] target is: 61\n",
            "when context is: [0, 26, 53, 61] target is: 1\n",
            "when context is: [0, 26, 53, 61, 1] target is: 57\n",
            "when context is: [0, 26, 53, 61, 1, 57] target is: 61\n",
            "when context is: [0, 26, 53, 61, 1, 57, 61] target is: 39\n",
            "when context is: [0, 26, 53, 61, 1, 57, 61, 39] target is: 50\n",
            "when context is: [1] target is: 52\n",
            "when context is: [1, 52] target is: 39\n",
            "when context is: [1, 52, 39] target is: 51\n",
            "when context is: [1, 52, 39, 51] target is: 43\n",
            "when context is: [1, 52, 39, 51, 43] target is: 1\n",
            "when context is: [1, 52, 39, 51, 43, 1] target is: 40\n",
            "when context is: [1, 52, 39, 51, 43, 1, 40] target is: 43\n",
            "when context is: [1, 52, 39, 51, 43, 1, 40, 43] target is: 1\n",
            "when context is: [0] target is: 25\n",
            "when context is: [0, 25] target is: 17\n",
            "when context is: [0, 25, 17] target is: 26\n",
            "when context is: [0, 25, 17, 26] target is: 17\n",
            "when context is: [0, 25, 17, 26, 17] target is: 26\n",
            "when context is: [0, 25, 17, 26, 17, 26] target is: 21\n",
            "when context is: [0, 25, 17, 26, 17, 26, 21] target is: 33\n",
            "when context is: [0, 25, 17, 26, 17, 26, 21, 33] target is: 31\n",
            "when context is: [13] target is: 16\n",
            "when context is: [13, 16] target is: 37\n",
            "when context is: [13, 16, 37] target is: 1\n",
            "when context is: [13, 16, 37, 1] target is: 19\n",
            "when context is: [13, 16, 37, 1, 19] target is: 30\n",
            "when context is: [13, 16, 37, 1, 19, 30] target is: 17\n",
            "when context is: [13, 16, 37, 1, 19, 30, 17] target is: 37\n",
            "when context is: [13, 16, 37, 1, 19, 30, 17, 37] target is: 10\n",
            "when context is: [1] target is: 59\n",
            "when context is: [1, 59] target is: 54\n",
            "when context is: [1, 59, 54] target is: 1\n",
            "when context is: [1, 59, 54, 1] target is: 58\n",
            "when context is: [1, 59, 54, 1, 58] target is: 46\n",
            "when context is: [1, 59, 54, 1, 58, 46] target is: 43\n",
            "when context is: [1, 59, 54, 1, 58, 46, 43] target is: 1\n",
            "when context is: [1, 59, 54, 1, 58, 46, 43, 1] target is: 51\n",
            "when context is: [45] target is: 46\n",
            "when context is: [45, 46] target is: 52\n",
            "when context is: [45, 46, 52] target is: 43\n",
            "when context is: [45, 46, 52, 43] target is: 57\n",
            "when context is: [45, 46, 52, 43, 57] target is: 57\n",
            "when context is: [45, 46, 52, 43, 57, 57] target is: 6\n",
            "when context is: [45, 46, 52, 43, 57, 57, 6] target is: 1\n",
            "when context is: [45, 46, 52, 43, 57, 57, 6, 1] target is: 54\n",
            "when context is: [53] target is: 10\n",
            "when context is: [53, 10] target is: 0\n",
            "when context is: [53, 10, 0] target is: 61\n",
            "when context is: [53, 10, 0, 61] target is: 46\n",
            "when context is: [53, 10, 0, 61, 46] target is: 63\n",
            "when context is: [53, 10, 0, 61, 46, 63] target is: 6\n",
            "when context is: [53, 10, 0, 61, 46, 63, 6] target is: 1\n",
            "when context is: [53, 10, 0, 61, 46, 63, 6, 1] target is: 58\n",
            "when context is: [48] target is: 53\n",
            "when context is: [48, 53] target is: 47\n",
            "when context is: [48, 53, 47] target is: 52\n",
            "when context is: [48, 53, 47, 52] target is: 5\n",
            "when context is: [48, 53, 47, 52, 5] target is: 42\n",
            "when context is: [48, 53, 47, 52, 5, 42] target is: 0\n",
            "when context is: [48, 53, 47, 52, 5, 42, 0] target is: 14\n",
            "when context is: [48, 53, 47, 52, 5, 42, 0, 14] target is: 63\n",
            "when context is: [42] target is: 8\n",
            "when context is: [42, 8] target is: 0\n",
            "when context is: [42, 8, 0] target is: 0\n",
            "when context is: [42, 8, 0, 0] target is: 19\n",
            "when context is: [42, 8, 0, 0, 19] target is: 24\n",
            "when context is: [42, 8, 0, 0, 19, 24] target is: 27\n",
            "when context is: [42, 8, 0, 0, 19, 24, 27] target is: 33\n",
            "when context is: [42, 8, 0, 0, 19, 24, 27, 33] target is: 15\n",
            "when context is: [46] target is: 39\n",
            "when context is: [46, 39] target is: 58\n",
            "when context is: [46, 39, 58] target is: 1\n",
            "when context is: [46, 39, 58, 1] target is: 24\n",
            "when context is: [46, 39, 58, 1, 24] target is: 43\n",
            "when context is: [46, 39, 58, 1, 24, 43] target is: 61\n",
            "when context is: [46, 39, 58, 1, 24, 43, 61] target is: 47\n",
            "when context is: [46, 39, 58, 1, 24, 43, 61, 47] target is: 57\n",
            "when context is: [43] target is: 56\n",
            "when context is: [43, 56] target is: 43\n",
            "when context is: [43, 56, 43] target is: 2\n",
            "when context is: [43, 56, 43, 2] target is: 0\n",
            "when context is: [43, 56, 43, 2, 0] target is: 0\n",
            "when context is: [43, 56, 43, 2, 0, 0] target is: 14\n",
            "when context is: [43, 56, 43, 2, 0, 0, 14] target is: 33\n",
            "when context is: [43, 56, 43, 2, 0, 0, 14, 33] target is: 15\n",
            "when context is: [35] target is: 43\n",
            "when context is: [35, 43] target is: 50\n",
            "when context is: [35, 43, 50] target is: 41\n",
            "when context is: [35, 43, 50, 41] target is: 53\n",
            "when context is: [35, 43, 50, 41, 53] target is: 51\n",
            "when context is: [35, 43, 50, 41, 53, 51] target is: 43\n",
            "when context is: [35, 43, 50, 41, 53, 51, 43] target is: 6\n",
            "when context is: [35, 43, 50, 41, 53, 51, 43, 6] target is: 1\n",
            "when context is: [26] target is: 34\n",
            "when context is: [26, 34] target is: 27\n",
            "when context is: [26, 34, 27] target is: 24\n",
            "when context is: [26, 34, 27, 24] target is: 21\n",
            "when context is: [26, 34, 27, 24, 21] target is: 27\n",
            "when context is: [26, 34, 27, 24, 21, 27] target is: 10\n",
            "when context is: [26, 34, 27, 24, 21, 27, 10] target is: 0\n",
            "when context is: [26, 34, 27, 24, 21, 27, 10, 0] target is: 32\n",
            "when context is: [57] target is: 1\n",
            "when context is: [57, 1] target is: 40\n",
            "when context is: [57, 1, 40] target is: 50\n",
            "when context is: [57, 1, 40, 50] target is: 47\n",
            "when context is: [57, 1, 40, 50, 47] target is: 52\n",
            "when context is: [57, 1, 40, 50, 47, 52] target is: 42\n",
            "when context is: [57, 1, 40, 50, 47, 52, 42] target is: 1\n",
            "when context is: [57, 1, 40, 50, 47, 52, 42, 1] target is: 44\n",
            "when context is: [58] target is: 46\n",
            "when context is: [58, 46] target is: 43\n",
            "when context is: [58, 46, 43] target is: 56\n",
            "when context is: [58, 46, 43, 56] target is: 1\n",
            "when context is: [58, 46, 43, 56, 1] target is: 57\n",
            "when context is: [58, 46, 43, 56, 1, 57] target is: 58\n",
            "when context is: [58, 46, 43, 56, 1, 57, 58] target is: 39\n",
            "when context is: [58, 46, 43, 56, 1, 57, 58, 39] target is: 63\n",
            "when context is: [51] target is: 39\n",
            "when context is: [51, 39] target is: 50\n",
            "when context is: [51, 39, 50] target is: 50\n",
            "when context is: [51, 39, 50, 50] target is: 1\n",
            "when context is: [51, 39, 50, 50, 1] target is: 39\n",
            "when context is: [51, 39, 50, 50, 1, 39] target is: 50\n",
            "when context is: [51, 39, 50, 50, 1, 39, 50] target is: 43\n",
            "when context is: [51, 39, 50, 50, 1, 39, 50, 43] target is: 8\n",
            "when context is: [43] target is: 58\n",
            "when context is: [43, 58] target is: 41\n",
            "when context is: [43, 58, 41] target is: 46\n",
            "when context is: [43, 58, 41, 46] target is: 1\n",
            "when context is: [43, 58, 41, 46, 1] target is: 57\n",
            "when context is: [43, 58, 41, 46, 1, 57] target is: 46\n",
            "when context is: [43, 58, 41, 46, 1, 57, 46] target is: 56\n",
            "when context is: [43, 58, 41, 46, 1, 57, 46, 56] target is: 47\n",
            "when context is: [39] target is: 51\n",
            "when context is: [39, 51] target is: 1\n",
            "when context is: [39, 51, 1] target is: 63\n",
            "when context is: [39, 51, 1, 63] target is: 53\n",
            "when context is: [39, 51, 1, 63, 53] target is: 59\n",
            "when context is: [39, 51, 1, 63, 53, 59] target is: 56\n",
            "when context is: [39, 51, 1, 63, 53, 59, 56] target is: 57\n",
            "when context is: [39, 51, 1, 63, 53, 59, 56, 57] target is: 1\n",
            "when context is: [1] target is: 58\n",
            "when context is: [1, 58] target is: 46\n",
            "when context is: [1, 58, 46] target is: 43\n",
            "when context is: [1, 58, 46, 43] target is: 1\n",
            "when context is: [1, 58, 46, 43, 1] target is: 57\n",
            "when context is: [1, 58, 46, 43, 1, 57] target is: 46\n",
            "when context is: [1, 58, 46, 43, 1, 57, 46] target is: 43\n",
            "when context is: [1, 58, 46, 43, 1, 57, 46, 43] target is: 54\n",
            "when context is: [43] target is: 1\n",
            "when context is: [43, 1] target is: 53\n",
            "when context is: [43, 1, 53] target is: 56\n",
            "when context is: [43, 1, 53, 56] target is: 1\n",
            "when context is: [43, 1, 53, 56, 1] target is: 61\n",
            "when context is: [43, 1, 53, 56, 1, 61] target is: 39\n",
            "when context is: [43, 1, 53, 56, 1, 61, 39] target is: 56\n",
            "when context is: [43, 1, 53, 56, 1, 61, 39, 56] target is: 8\n",
            "when context is: [58] target is: 56\n",
            "when context is: [58, 56] target is: 47\n",
            "when context is: [58, 56, 47] target is: 49\n",
            "when context is: [58, 56, 47, 49] target is: 43\n",
            "when context is: [58, 56, 47, 49, 43] target is: 57\n",
            "when context is: [58, 56, 47, 49, 43, 57] target is: 58\n",
            "when context is: [58, 56, 47, 49, 43, 57, 58] target is: 1\n",
            "when context is: [58, 56, 47, 49, 43, 57, 58, 1] target is: 51\n",
            "when context is: [1] target is: 51\n",
            "when context is: [1, 51] target is: 43\n",
            "when context is: [1, 51, 43] target is: 56\n",
            "when context is: [1, 51, 43, 56] target is: 41\n",
            "when context is: [1, 51, 43, 56, 41] target is: 43\n",
            "when context is: [1, 51, 43, 56, 41, 43] target is: 52\n",
            "when context is: [1, 51, 43, 56, 41, 43, 52] target is: 39\n",
            "when context is: [1, 51, 43, 56, 41, 43, 52, 39] target is: 56\n",
            "when context is: [26] target is: 15\n",
            "when context is: [26, 15] target is: 17\n",
            "when context is: [26, 15, 17] target is: 10\n",
            "when context is: [26, 15, 17, 10] target is: 0\n",
            "when context is: [26, 15, 17, 10, 0] target is: 13\n",
            "when context is: [26, 15, 17, 10, 0, 13] target is: 1\n",
            "when context is: [26, 15, 17, 10, 0, 13, 1] target is: 50\n",
            "when context is: [26, 15, 17, 10, 0, 13, 1, 50] target is: 47\n",
            "when context is: [58] target is: 1\n",
            "when context is: [58, 1] target is: 21\n",
            "when context is: [58, 1, 21] target is: 1\n",
            "when context is: [58, 1, 21, 1] target is: 61\n",
            "when context is: [58, 1, 21, 1, 61] target is: 53\n",
            "when context is: [58, 1, 21, 1, 61, 53] target is: 59\n",
            "when context is: [58, 1, 21, 1, 61, 53, 59] target is: 50\n",
            "when context is: [58, 1, 21, 1, 61, 53, 59, 50] target is: 42\n",
            "when context is: [52] target is: 43\n",
            "when context is: [52, 43] target is: 1\n",
            "when context is: [52, 43, 1] target is: 43\n",
            "when context is: [52, 43, 1, 43] target is: 63\n",
            "when context is: [52, 43, 1, 43, 63] target is: 43\n",
            "when context is: [52, 43, 1, 43, 63, 43] target is: 57\n",
            "when context is: [52, 43, 1, 43, 63, 43, 57] target is: 8\n",
            "when context is: [52, 43, 1, 43, 63, 43, 57, 8] target is: 1\n",
            "when context is: [1] target is: 39\n",
            "when context is: [1, 39] target is: 52\n",
            "when context is: [1, 39, 52] target is: 42\n",
            "when context is: [1, 39, 52, 42] target is: 1\n",
            "when context is: [1, 39, 52, 42, 1] target is: 41\n",
            "when context is: [1, 39, 52, 42, 1, 41] target is: 53\n",
            "when context is: [1, 39, 52, 42, 1, 41, 53] target is: 59\n",
            "when context is: [1, 39, 52, 42, 1, 41, 53, 59] target is: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    # compute the attention scores ('affinities)\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) ---> (B, T, T) , used scaled attention here\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) , this is part of decoder so does not communicate with past\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    # perform the weighted aggregation of values\n",
        "    v = self.value(x) # (B, T, C)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, C) --> (B, T, C)\n",
        "    return out"
      ],
      "metadata": {
        "id": "-cwnxNTblqHO"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Multi head attention\"\"\"\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "    self.head = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([h(x) for h in self.head], dim=-1) # concatenate along the channel dimension, i.e last dimension"
      ],
      "metadata": {
        "id": "w42p4tEEs7zV"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  \"\"\"Simple linear layer followed by non linearilty\"\"\"\n",
        "\n",
        "  def __init__(self, n_embed):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embed, n_embed),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "m1JFBjcRxEPA"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "  def __init__(self, n_embed, n_head):\n",
        "    super().__init__()\n",
        "    # n_embed: embedding dimension, n_head: the number of heads we'd like\n",
        "    head_size = n_embed // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size)\n",
        "    self.ffwd = FeedForward(n_embed)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sa(x)\n",
        "    x = self.ffwd(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "mASby3mby_oS"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1033)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BigramLanguageModel, self).__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "    self.blocks = nn.Sequential(Block(n_embed, n_head=4),\n",
        "        Block(n_embed, n_head=4),\n",
        "        Block(n_embed, n_head=4)\n",
        "    )\n",
        "    self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "  def forward(self, idx, target=None):\n",
        "    B, T = idx.shape\n",
        "\n",
        "    # idx and targets are both (B,T) tensors of integer\n",
        "    token_embed = self.token_embedding_table(idx) # (B,T,C) where C is n_embed\n",
        "    pos_embed = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
        "    X = token_embed + pos_embed # (B, T, C)\n",
        "    X = self.blocks(X) #(B, T, C)\n",
        "    logits = self.lm_head(X) # (B, T, Vocab_size)\n",
        "\n",
        "    if target is not None:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      target = target.view(-1) # or target.view(B*T)\n",
        "      loss = F.cross_entropy(logits, target)\n",
        "\n",
        "    else:\n",
        "      loss = None\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_char):\n",
        "    #idx is (B, T) array of indices in current context\n",
        "    for _ in range(max_new_char):\n",
        "      # print(idx.shape)\n",
        "      # print(idx)\n",
        "      # crop idx to the last block_size tokens\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "      # print(idx_cond)\n",
        "      # get the predictions\n",
        "      logits, loss = self(idx_cond)\n",
        "      # Focus only on last time step\n",
        "      logits = logits[:, -1, :] # becomes [B, C]\n",
        "      # apply softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # (B,C)\n",
        "      # sample from distribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
        "      # append sampled index to running index\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # (b , T+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel()\n",
        "logits, loss = m(xb, yb)\n",
        "# print(logits.shape)\n",
        "# print(loss)\n",
        "# start_token = torch.zeros((1,1), dtype=torch.long)\n",
        "# print(decode(m.generate(start_token, 100)[0].tolist()))"
      ],
      "metadata": {
        "id": "dCBWT27Ve-ne"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Optimizer\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr = lr_rate)"
      ],
      "metadata": {
        "id": "GfcK2gMlhpKB"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      xb, yb = get_batch(split)\n",
        "      logits, loss = m(xb, yb)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "xZAU4HsLG2qk"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for steps in range(max_iters):\n",
        "\n",
        "  if steps % eval_interval == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {steps}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')\n",
        "  logits, loss = m(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_stjVIvswLJ",
        "outputId": "9635c3c7-741f-49d9-d1c3-63a1090451d2"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.1530, val loss 4.1547\n",
            "step 500: train loss 3.1124, val loss 3.1164\n",
            "step 1000: train loss 2.7853, val loss 2.7867\n",
            "step 1500: train loss 2.6315, val loss 2.6270\n",
            "step 2000: train loss 2.5239, val loss 2.5395\n",
            "step 2500: train loss 2.4592, val loss 2.4558\n",
            "step 3000: train loss 2.4084, val loss 2.4031\n",
            "step 3500: train loss 2.3598, val loss 2.3644\n",
            "step 4000: train loss 2.3315, val loss 2.3514\n",
            "step 4500: train loss 2.3026, val loss 2.3036\n",
            "2.3015568256378174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1,1), dtype=torch.long)\n",
        "print(decode(m.generate(start_token, 1000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoMlsmthvfuV",
        "outputId": "6b3a7e72-5eea-45b5-cb22-67bd7b1e5e15"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Lhat tloy py it shud at mom averld she o thy awilrs hat?\n",
            "Kaye offhat youal.\n",
            "IOVES:\n",
            "Thoud?\n",
            "\n",
            "Merant, sprnave sud shen demen\n",
            "Bhat I twicte miwined as the yave of his, the wiseare grleit noo, mis chiveg gry yous nove sew\n",
            "An the suea omwy prepove ive sume sheden becor'lt day lark make hi spe dee-Rtimee whane fims me whas o's grov thall whe then yel of preer,\n",
            "Thom he our alle, neses novy nes, I me-\n",
            "Whee, -my not lothe I horp ins heate wouny whe his relss are ade ex my pare the by ther at ming.\n",
            "Namive nur.\n",
            "\n",
            "CA Whouns.\n",
            "\n",
            "MERN:\n",
            "Cher alke aseam, pry bedeank I thun share thy lelat men ttoul stame fheveles toood deth this lis Bud me!\n",
            "He ther?\n",
            "Thats:\n",
            "I vaun loldine,' le wives? fon? \n",
            "Loughsse?\n",
            "\n",
            "Vouchne wovean,\n",
            "wher of nos carls?\n",
            "\n",
            "Moube us stile frome he'r whatt got nouv tous uw wy of gou\n",
            "gol mirt rousttie; shis we aan lis thore Thy for me,\n",
            "Lenoseg eoa bry lick qoomer Ey coome of ile khes yopes, whered swrerem ad hhesing I fe.\n",
            "Ceven, Yeshigh'aid nomy iw we whast Intrae, dor mouve aly thires ad rew\n",
            "Itt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtCxdNYlv7te"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}